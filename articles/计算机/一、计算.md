# 一、计算

## 1. 第三次工业革命

* 第一次工业革命：蒸汽机，能源：煤炭
* 第二次工业革命：发电机，能源：电
* 第三次工业革命：计算机，能源：计算
* 第四次工业革命：人工智能，能源：数据

## 2. 计算能源：芯片

电能供给芯片，芯片的电子元件晶振通电后产生震荡，震荡会产生频率稳定的每秒百万次的高频脉冲信号，我们通过谐振效应发送这个信号形成方波，再通过电子元件调整这个脉冲的频率将脉冲信号转换成我们需要的频率，这就形成了驱动芯片工作的时钟信号，也称作芯片的时钟频率，时钟信号驱动着芯片工作，每一次脉冲都会让芯片的状态发生一次变化，最终存储器中的指令被一次次执行，`指令被执行其实就是数据被计算`，这就是计算能源

芯片被普及后，不仅给计算机提供支持，还被安装到了手机、航天设备、能源设备、医疗设备、通信设备、电灯、微波炉、咖啡机、热水器等等，`有了芯片后设备通电才能计算，有了计算后设备才能实现复杂而精确的功能`

## 3. 计算能源的发展：摩尔定律

历史上是`先有计算机再有芯片`

这就好比程序员`先实现产品功能，再考虑封装和复用`，最开始的计算机中负责计算的模块和后来的芯片原理是一样的，都是`利用电路实现逻辑运算`，只不过那个时候的人们还没有能力将这个计算模块抽象成一个独立的产品，也无法解决电路体积的问题

### (1) 电子元件越来越多

芯片的计算能力来源于`芯片内部的集成电路`，集成电路大大减少了电路的体积，将所有电路都集成到一个单一的硅片上，为了提高计算性能，集成电路越来越复杂，里面的电子元件越来越多，到现在已经是拥有上亿电子元件的巨大规模集成电路

#### 摩尔定律

那个时代摩尔观察到了这个现象并提出了摩尔定律：当价格不变时，集成电路中可容纳的晶体管数目约每隔 18～24 个月就会增加一倍，性能也将提升一倍

### (2) 核心越来越多

#### 摩尔定律的失效

随着芯片越来越小，在`尺寸和散热`等方面已经挑战了人类的极限，芯片中无法再放入更多的电子元件了

#### 计算能力的另一种发展

一个普通的显卡中拥有几百个核心从而可以进行大量的`并发计算`，一个分布式的大数据集群就有上千个核心

## 4. 可计算理论：图灵机

计算可以用来做什么？例如做饭可不可以被计算？

20 世纪初的科学家们，在尝试发明计算机和芯片前，就需要想清楚这些问题，这并不是一件容易的事情

### (1) 希尔伯特公理化体系

19 世纪初，德国著名数学家希尔伯特提出希尔伯特公理化体系：这个世界可以建立一套完备的公理体系，由少数几个公理出发，推导出所有的定理和推论，这样就可以逐渐将世界上的万事万物都统一到一个体系中

当然这只是一个美好的设想，如果万事万物都可以用形式化的手段统一到一套体系中，也就意味着计算能力将被无限扩展，只要给出足够的时间和空间，计算机就可以完成任何工作

### (2) 哥德尔不完备性定理

不久之后美籍数学家哥德尔就提出了哥德尔不完备性定理：即便在完善的公理体系中，仍然可以找到`不能被证明的也不能被证伪`的命题

联想到一说谎鼻子就会变长的匹诺曹，如果他说：我说谎了，那么他的鼻子应该变长还是变短呢？对于人类而言这个问题可以理解，而对于计算机来说这个问题是不可计算的

正因为这个世界上存在着大量的公说公有理婆说婆有理的问题，大家才意识到计算不能解决所有问题，因此计算机的能力也是有边界的，哥德尔的不完备性定理，让大家看到了世界上还有大量不可计算的问题

### (3) 可计算理论

于是人们意识到需要一个可计算理论，专门回答`哪些问题可以被计算，哪些问题不可以被计算`这样的问题，可计算理论是计算机科学的理论基础之一

1936 年，人工智能之父阿兰·图灵提出了图灵机，图灵机是一种`不断执行指令的抽象计算机`，之所以说抽象，是因为这不是一台真正的计算机，而只是一个探讨可计算问题的`理论`

如果一个问题是可计算的，那么这个问题的解决方案就可以被具象化为`一条条指令`由图灵机处理，例如一个马达的控制程序可以被抽象为一条条指令，程序可以先读取传感器的数据，然后再根据数据计算出接下来要加速还是减速

## 5. 问题的分类

计算能力的边界

* 时间开销：解决问题需要消耗`芯片的计算能力`
* 空间开销：解决问题需要消耗`内存`

### (1) 不可计算问题

无论消耗多少时间和空间都无法解决的问题

* 不可计算问题一定比可计算问题多

### (2) 可计算问题

可计算问题通常用`复杂度`来衡量

* 求数组第 n 个元素：时间开销和空间开销都不会随着问题规模增长，记为 `O(1)`
* 求数组最大值：时间开销随着数组规模线性增大，记为 `O(N)`
* 求一个 n*n 矩阵的和：时间开销随着问题规模的平方增长，记为 `O(N^2)`
