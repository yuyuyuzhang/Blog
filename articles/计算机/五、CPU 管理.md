# 五、CPU 管理

## 1. 程序

### (1) 程序的顺序执行

多个程序`先后`执行，一个程序执行完才能执行下一个程序

一个应用程序由若干子程序组成，每个子程序完成特定的功能，子程序必须`按序执行`，例如必须先执行输入程序 I，再执行计算程序 C，最后执行打印程序 P，子程序的前驱图如下所示

![顺序执行](https://github.com/yuyuyuzhang/Blog/blob/master/images/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E9%A1%BA%E5%BA%8F%E6%89%A7%E8%A1%8C.png)

程序顺序执行的特征如下

* **顺序性**：CPU 严格按照应用程序规定的顺序执行，每个子程序必须在上一个子程序完成之后开始
* **封闭性**：程序在封闭的环境下运行，程序运行时独占全机资源，资源的状态只有本程序才能改变，程序一旦开始执行，其执行结果不受外界因素影响
* **可再现性**：只要程序执行时的环境和初始条件相同，程序重复执行时，无论是一气呵成地执行，还是走走停停的执行，都可以获得相同的结果

### (2) 程序的并行执行

多个程序在`同一时刻`执行

CPU 在同一时刻只能执行一个程序，因此单处理机只能`并发`执行内存中的多个程序，而多处理机可以`并行`执行内存中的多个程序

### (3) 程序的并发执行

多个程序在`同一时间间隔内`执行

内存中存在多个应用程序，每个应用程序都有输入程序 I、计算程序 C、打印程序 P 这三个子程序，I1 输入数据后，C1 进行计算，然后通过 `CPU 时间片轮转等调度方式`，执行 I2，从而使得 C1 和 I2 `并发`执行，也就使得第一个应用程序和第二个应用程序`并发`执行

![并发执行](https://github.com/yuyuyuzhang/Blog/blob/master/images/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E5%B9%B6%E5%8F%91%E6%89%A7%E8%A1%8C.png)

程序并发执行的特征如下

* **间断性**：系统的各种资源被并发执行的应用程序共享，致使并发程序间形成`相互制约`的关系，相互制约将导致并发程序具有 `执行-暂停-执行` 这种间歇性的活动规律，例如计算程序 C1 完成后，输入程序 I2 尚未完成，那么计算程序 C2 就只能暂停执行，等待输入程序 I2 完成后才能恢复执行
* **失去封闭性**：系统的各种资源被并发执行的应用程序共享，致使任一程序运行时，环境都必然会受到其他程序的影响，例如 CPU 分配给一个程序时，其他程序必须等待
* **不可再现性**：由于失去封闭性，将导致不可再现性

## 2. 进程

### (1) 进程的概念

由于并发执行的程序具有间断性，并且失去封闭性和可再现性，因此一般的程序是无法参与并发执行的，为了能对并发执行的程序加以控制，引入了进程这个概念

**进程控制块 PCB**：描述进程的基本情况和活动过程，进而控制和管理进程

**进程实体**：PCB、程序代码、相关的数据

**进程**：进程实体通常简称为进程，进程也被定义为`能独立运行并作为资源分配的基本单位`

### (2) 进程的属性

#### ① 进程是一个可拥有资源的基本单位

一个进程要能够独立运行，必须拥有一定的资源，例如存放程序和数据的内存或磁盘空间，运行时所需的 IO 设备等

#### ② 进程是一个可独立调度的基本单位（该属性转至线程）

一个进程要能够独立运行，还必须是一个可独立调度的基本单位，每个进程拥有唯一的 PCB，操作系统根据 PCB 感知进程的存在，利用 PCB 中的信息对进程进行调度，将断电信息保存在 PCB 中之后在利用其恢复进程运行的现场

### (3) 进程的特征

#### ① 动态性
  
程序是`一组有序指令的集合`，存放于磁盘等介质上，程序本身是静态的，并不具有活动的意义
  
进程是`程序及其数据的一次执行过程`，具有一定的生命期，进程由创建而产生，由调度而执行，由撤销而消亡

#### ② 并发性
  
多个进程同时存在于内存中，并且能在一段时间间隔内并发执行，凡是未建立 PCB 的程序都不能参与并发执行

进程并发执行的特性如下

* **间断性**：系统的各种资源被并发进程共享，致使并发进程间形成`相互制约`的关系，相互制约将导致并发进程具有 `执行-暂停-执行` 这种间歇性的活动规律，例如进程 A 请求使用打印机，而操作系统已经将打印机分配给其他进程，则进程 A 自动进入阻塞状态，等待打印机空闲时才被中断处理程序唤醒
* **失去封闭性**：系统的各种资源被并发进程共享，致使任一进程运行时，环境都必然会受到其他进程的影响，例如将 CPU 分配给一个进程，其他进程则必须等待
* **可再现性**：并发进程之间通过`同步机制`保证可再现性

#### ③ 独立性
  
进程是一个能`独立获得资源、独立接收调度和运行`的基本单位，凡是未建立 PCB 的程序都不能作为一个独立的单位参与运行

#### ④ 异步性
  
进程是按异步方式运行的，即进程是按各自独立的、不可预知的速度向前推进，而`进程同步`机制保证了进程并发执行的结果是`可再现`的

### (4) 进程的层次

#### ① Unix

Unix 系统中，允许父进程创建子进程，子进程再创建更多的孙进程，由此便形成了进程间的层次结构 ( 进程树 )

`子进程可以继承父进程的所有资源`，例如父进程打开的文件、分配到的缓存区等等，父进程无法拒绝子进程的继承权

撤销父进程时，也必须撤销其所有的子进程

![进程树](https://github.com/yuyuyuzhang/Blog/blob/master/images/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%BF%9B%E7%A8%8B%E6%A0%91.png)

#### ② Windows

Windows 系统中不存在进程层次结构的概念，所有的进程都具有相同的地位，进程 A 创建进程 B 时，进程 A 会获得一个`句柄`，用来控制进程 B，这个句柄是可以`传递`的，因此进程之间的关系不是层次关系，而是`获得句柄与否、控制与被控制`的关系

### (5) 进程的状态

由于多个进程在并发执行时共享资源，致使在运行过程中呈现 `执行-暂停-执行` 这种间歇性的活动规律，所以进程在其生命周期内具有多种基本状态

#### ① 创建状态

要执行一个应用程序时，先将其装入内存，为其创建进程，为新进程分配除 CPU 以外的所有必须资源，然后将新进程转为就绪状态并且插入就绪队列

#### ② 终止状态

一个进程到达了自然结束点、出现了无法克服的错误、被操作系统终止、被其他有权限的进程终止时，这个进程都将进入终止状态

#### ③ 就绪状态

进程已被分配到除 CPU 以外的所有必要资源，只要获得 CPU，进程便可以立即执行，所有就绪状态的进程按照优先级策略排列成`就绪队列`

#### ④ 执行状态

进程已获得 CPU 正在执行，一个 CPU 在任何时刻只能执行一个进程

#### ⑤ 阻塞状态

正在执行的进程由于发生某些事件暂时无法继续执行而自动阻塞，此时操作系统会把 CPU 分配给另一个就绪进程，所有阻塞状态的进程按照优先级策略排列成`阻塞队列`

![五种基本状态](https://github.com/yuyuyuzhang/Blog/blob/master/images/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E4%BA%94%E7%A7%8D%E5%9F%BA%E6%9C%AC%E7%8A%B6%E6%80%81.png)

### (6) 进程的调度

应用程序要在操作系统运行，必须先将其`从磁盘装入内存`，然后再为其创建进程

**① 编译**：编译程序将应用程序的源程序编译成若干目标模块

**② 链接**：链接程序将若干目标模块以及所需要的库函数链接在一起，形成一个完整的装入模块

**③ 装入**：装入程序将装入模块装入内存

![程序装入内存](https://github.com/yuyuyuzhang/Blog/blob/master/images/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%A8%8B%E5%BA%8F%E8%A3%85%E5%85%A5%E5%86%85%E5%AD%98.png)

## 3. 线程

### (1) 线程的引入

#### ② 进程并发执行的开销

为了能使进程并发执行，操作系统必须进行以下操作

* 创建进程：操作系统需要先申请空白 PCB，为新进程分配除 CPU 以外的所有必须资源，如内存空间、IO 设备等，然后初始化 CPB 填写用于控制和管理进程的信息，最后将新进程转为就绪状态并插入就绪队列
* 撤销进程：操作系统需要先终止进程，然后回收其所有的资源，最后再将进程 PCB 从所在进程队列移出
* 进程切换：操作系统需要先将当前进程的 CPU 环境保留到其 PCB 中，然后再为新选中进程设置 CPU 环境，因此需要花费不少的 CPU 时间

#### ② 引入线程的目的

由上述可知，进程是一个资源的拥有者，因此在创建、撤销、切换进程时，操作系统必须为之付出较大的开销，这就限制了并发进程的数目，并且进程切换也不宜过于频繁，从而限制了并发程度的进一步提高

因此引入了线程的概念，线程是为了减少并发进程执行时操作系统付出的开销，使操作系统具有更好的并发性

### (2) 线程的概念

引入线程的实质就是`将进程的两个基本属性分开`，由操作系统分开处理

引入多线程的操作系统中，进程将不再作为可独立调度的基本单位，因此`进程也就不再作为可执行的实体`，但是进程仍然具有五种状态，例如进程处于执行状态，表示进程至少有一个线程处于执行状态

* **进程**：进程是一个`可拥有资源`的基本单位
* **线程**：线程是一个`可独立调度`的基本单位（从进程的 2 个基本属性中分离出）

**线程控制块 TCB**：描述线程的基本情况和活动过程，进而控制和管理线程

**线程实体**：TCB、程序代码，相关的数据

进程和线程的比较如下

* **拥有资源**：进程作为拥有资源的基本单位，线程本身并不拥有`系统资源`，而是拥有自己的必不可少的、能保证独立运行的`资源`（线程控制块 TCB、程序代码、相关数据），但是同一进程的所有线程共享该进程拥有的系统资源
* **调度的基本单位**：线程作为调度的基本单位，进程不再作为调度的基本单位，同一进程中线程的切换不会引起进程的切换，而从一个进程中的线程切换到另一个进程中的线程会引起进程的切换
* **并发性**：多个进程之间可以并发执行，同一进程的多个线程之间也可以并发执行，例如文字处理进程可以设置三个线程，一个用于从键盘读取数据，一个用于在后台进行拼写和语法检查，一个用于显示文字和图片
* **独立性**：不同进程间都拥有独立的地址空间和其他资源，除了共享全局变量外，不允许其他进程的访问，而同一进程的所有线程共享该进程的所有资源，因此线程的独立性更低

### (3) 线程的状态

① 线程与进程一样，同样拥有五种基本状态：创建状态、终止状态、就绪状态、执行状态、阻塞状态

② 线程也具有挂起和激活操作

![线程状态](https://github.com/yuyuyuzhang/Blog/blob/master/images/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81.png)

### (4) 线程的调度

线程分配 CPU 的方式就是由操作系统调度线程，操作系统创建一个进程后，进程的`入口程序`被分配到了一个`主线程`执行，这样看上去是操作系统在调度进程，实际上是`操作系统调度进程的主线程`

这种被操作系统直接调度的线程，称为`内核级线程`，有的应用程序的程序员自己还实现了线程，相当于操作系统调度主线程，主线程的程序用算法实现了子线程，这种子线程就被称为`用户级线程`

#### ① 先到先服务（First Come First Service，FCFS）

早期的操作系统是一个个处理作业，使用先到先服务算法，先到的作业先计算，后到的作业排队进行，这里用到的数据结构是先进先出的`队列`

* **公平性**：从公平性来说这个算法非常朴素，一个作业完成才会进行下一个作业，作业之间不会进行切换
* **吞吐量**：从吞吐量来说是最优秀的，因为没有额外开销

#### ② 短作业优先（Shortest Job First，SJF）

先到先服务算法对于等待的作业来说是有问题的，例如一个需要用时一天的作业等待了一个小时是可以接受的，而一个用时一个小时的作业等待了一天是不能接受的，因此应该优先处理用时少的

短作业优先算法会同时考虑`作业到来顺序`和`作业预估时间`

* **平均等待时间**：总等待时间 / 任务数
* **用户满意度**：平均等待时间和用户满意度是成反比的，平均等待时间越长用户越不满意，因此大多数情况下都应该优先处理用时少的，从而降低平均等待时间，提高用户满意度

![短作业优先](https://github.com/yuyuyuzhang/Blog/blob/master/images/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%9F%AD%E4%BD%9C%E4%B8%9A%E4%BC%98%E5%85%88.png)

* 按照 3 3 10 的顺序处理：平均等待时间 =（0 + 3 + 6）/ 3 = 3 分钟
* 按照 10 3 3 的顺序处理：平均等待时间 =（0 + 10 + 13）/ 3 = 7.66 分钟

#### ③ 优先级队列（PriorityQueue）

短作业优先算法对于优先级高的作业来说是有问题的，例如老板安排的任务需要紧急插队怎么办？

优先级队列算法是给队列中每个作业排一个优先级，优先级高的作业先执行，这里用到的数据结构是`堆`，堆可以在 `O(1)` 的时间复杂度内找到优先级最高的作业，而对于优先级相同的作业，就需要按照`短作业优先算法`执行了

* **优先级高**：先执行
* **优先级相同**：短作业优先

#### ④ 抢占（Preemption）

优先级队列算法对于`先执行的长任务导致后到来的短任务没有执行`怎么办？

抢占算法是将 CPU 执行能力分成`时间片段`，让每个任务都按照`优先级队列算法`执行一个时间片段，时间片段内任务完成就调度下一个任务，没有完成就`中断`任务，让所有任务`重新排队`并调度下一个任务

#### ⑤ 基本线程调度模型

`抢占算法 + 优先级队列算法 + 短作业优先算法`就构成了一个基本的线程调度模型，操作系统为每个到来的线程排一个优先级，然后放入一个优先级队列，优先级高的线程先执行，优先级相同的线程按照短作业优先算法执行，每个线程执行一个 CPU 时间片段，每次执行完一个线程就执行一段调度程序，调度程序将没有完成的所有线程重新排序后再次调度

![基本线程调度模型](https://github.com/yuyuyuzhang/Blog/blob/master/images/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E5%9F%BA%E6%9C%AC%E7%BA%BF%E7%A8%8B%E8%B0%83%E5%BA%A6%E6%A8%A1%E5%9E%8B.png)

#### ⑥ 多级队列线程调度模型

如下图设计了两级队列线程调度模型，上层队列调度紧急任务，下层队列调度普通任务，只要上层队列有任务，下层队列就会让出执行权限

* **高优先级队列**：优先级队列算法
  * 优先级高的线程先执行
  * 所有紧急线程按照优先级处理，不考虑抢占
* **低优先级队列**：抢占算法 + 优先级队列算法
  * 优先级高的线程先执行，每个线程执行一个 CPU 时间片段，每次执行完一个线程就执行一段调度程序，调度程序将没有完成的所有线程重新排序后再次调度
  * 每执行一个 CPU 时间片段就可以判断一下高优先级队列是否有线程

![两级队列线程调度模型](https://github.com/yuyuyuzhang/Blog/blob/master/images/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E4%B8%A4%E7%BA%A7%E9%98%9F%E5%88%97%E7%BA%BF%E7%A8%8B%E8%B0%83%E5%BA%A6%E6%A8%A1%E5%9E%8B.png)

两级队列线程调度模型没有解决`短作业优先`的问题，如下图设计了多级队列线程调度模型

* 紧急任务仍然走高优队列，非抢占执行
* 普通任务先放到优先级仅次于高优任务的队列中，并且只分配很小的时间片
  * 如果执行完成，说明任务很短
  * 如果没有执行完成，说明任务不是很短，就将任务`下调一层`，下面一层低优先级的队列中时间片很大，长任务就有更大的时间片可以用，通过这种方式，短任务会在更高优先级的队列中执行完成，长任务优先级会下调，也就类似实现了短作业优先算法
* 实际操作中可以有 n 层，一层层把大任务筛选出来，最长的任务放到最闲的时间执行，大部分时间 CPU 不是满负荷的

![多级队列线程调度模型](https://github.com/yuyuyuzhang/Blog/blob/master/images/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E5%A4%9A%E7%BA%A7%E9%98%9F%E5%88%97%E7%BA%BF%E7%A8%8B%E8%B0%83%E5%BA%A6%E6%A8%A1%E5%9E%8B.png)

## 4. 线程同步

### (1) 线程同步机制

#### ① 线程同步机制

线程同步机制是为了保证进程和线程的`可再现性`，对多个并发线程的执行次序进行协调，使并发线程能按照一定的规则共享系统资源

* **原子操作**：原子操作就是`操作不可分`，在多线程环境下，一个原子操作的操作过程`无法被中断`

  例如 i++ 就是由三个原子操作组成的非原子操作

  * 读取 i
  * 计算 i+1
  * 写入新值

  这种非原子操作在`多线程 + 多核环境`下会造成`竞争条件`

* **竞争条件**：多个线程对同一资源的读写存在竞争，因此这个资源的最终值不可预测，取决于竞争时的具体执行顺序

  例如 2 个线程并发执行 i++，如果按照以下顺序执行，即使执行 2 次 i++，但最终 i=1

  ![竞争条件](https://github.com/yuyuyuzhang/Blog/blob/master/images/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E7%AB%9E%E4%BA%89%E6%9D%A1%E4%BB%B6.png)

* **临界资源**：一段时间内只允许`指定数量线程`访问的资源
  * 软件临界资源：变量、表格、栈等
  * 硬件临界资源：打印机等诸多物理设备
* **临界区**：每个线程中访问临界资源的`程序代码片段`

  例如 i++ 这段程序访问了共享资源变量 i，那么 i++ 这个程序片段就是临界区

#### ② 线程同步机制应遵循的规则

* **空闲让进**：当无线程处于临界区时，表示临界资源处于空闲状态，应该允许一个请求进入临界区的线程进入自己的临界区，访问临界资源
* **忙则等待**：当已有线程处于临界区时，表示临界资源正在被访问，因此所有请求进入临界区的线程都必须等待
* **有限等待**：请求进入临界区的线程，应保证在有限时间内进入自己的临界区，避免死等
* **让权等待**：当线程不能进入自己的临界区时，应立即释放 CPU，避免忙等

### (2) 互斥/悲观锁

悲观锁同时只允许 `1` 个线程进入临界区，让临界区互斥，具有强烈的排他性，对修改持保守态度

### (3) 信号量机制

信号量同时允许`给定数量`的线程进入临界区，其实就是给临界资源上 n 把锁，先到的线程就取一把钥匙，出来时再把钥匙挂回原处，后到的线程发现钥匙架空了就在门口排队

### (3) 乐观锁

乐观锁同时允许`所有`线程进入临界区，例如版本控制工具 Git，允许大家一起编辑，各自将结果存在本地，但都可以向远程仓库提交，如果没有版本冲突就可以提交成功，否则会提交失败，先提交的人被采纳，后提交的人负责解决冲突

例如 Git 仓库当前版本为 100，A 和 B 将版本 100 拷贝到本地同时修改代码，A 修改到版本 101，B 修改到版本 102，如果 A 先提交，当前 Git 仓库版本为 101，此时 B 再提交就会失败，因为版本已经不是 100 而是 101，B 就需要将最新版本 101 的代码 fetch 到本地，然后合并冲突，再尝试提交一个更新的版本 103

```js
cas(&version, 100, 101); // 成功
cas(&version, 100, 102); // 失败，因为此时 version 是 101
```

### (4) 区块链

传统的架构之所以害怕并发，是因为`中心化`

例如淘宝双十一，用户可以直接和商家下单，而不需要通过淘宝的中心系统，这就相当于实现了同步，这是一个去中心化的方案，让业务不需要集中处理

#### ① 信用问题

`电子合同`技术实现了用户直接和商家签订合同，无需平台的中心系统下单
  
例如 A 向苹果店 B 购买了一个 iphone，那么双方签订的电子合同 C 如下

```js
//A同意给B转10000块钱，如果A收到了phone不给B打钱，B就可以拿着这个电子合同去法院告A，因为这个电子合同具有A的签名
1、from=A，to=B，price=10000，signature=A的签名

//B同意给A一个phone，如果B收到了A的钱不给A一个phone，A就可以拿着这个电子合同去法院告B，因为这个电子合同具有B的签名
2、from=B，to=A，object=phone，signature=B的签名
```

#### ② 货币和库存的问题

A 如何证明自己有足够的钱买 iphone？B 如何证明自己有足够的 iphone？
  
在某个对外开放的节点中记录了以下信息，假如全世界所有人的钱都放在这个系统里，这样就无需关心钱从哪里来，这样的结构也叫做区块链，每个 block 下可以存储一些数据，每个 block 知道上一个节点是谁，也有上一个节点的摘要签名，可以证明上一个节点的数据没有被篡改过

区块链构成了一个`基于历史版本的事实链`，前一个版本是后一个版本的历史

```js
1、account=A，money=20000
2、account=B，iphone=100
...
```

![货币和库存的问题](https://github.com/yuyuyuzhang/Blog/blob/master/images/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%B4%A7%E5%B8%81%E5%92%8C%E5%BA%93%E5%AD%98%E7%9A%84%E9%97%AE%E9%A2%98.png)

#### ③ 购买转账的问题

A 向苹果店 B 购买了 iphone，需要提交电子合同的 2 条新数据到上面的区块链
  
那么我们可以在末端节点上再增加一个区块表示这次交易，例如 A 先在本地完成这件事，本地的区块链就会像上图所示，假如有一个中心化服务器，专门接受这些区块数据，A 接下来就可以将数据提交到中心化服务器，苹果店 B 从中心化服务器看到这条信息，认为交易被 A 执行了，就可以准备发货

如果世界上有很多人同时在这个末端节点上写新的 block，就可以考虑由一个可信任的中心服务帮助合并新增的区块数据，例如 Git 由很多人同时修改代码，先提交的被采纳，后提交的负责解决冲突，避免同时操作产生混乱

![购买转账的问题](https://github.com/yuyuyuzhang/Blog/blob/master/images/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%B4%AD%E4%B9%B0%E8%BD%AC%E8%B4%A6%E7%9A%84%E9%97%AE%E9%A2%98.png)

#### ④ 欺诈问题

正常情况下所有记录都可以被合并，例如 A 在一家苹果店 B 购买了 1 个 iphone，在另一家苹果店 C 购买了 2 个 iphone，而 A 只有 20000 块钱，这时 A 的钱就不够付款了，如果 A 想用 20000 块钱买 3 个 iphone，就需要修改自己的余额，那么 A 如何做？

A 需要新增一个末端节点，在末端节点上修改自己的余额为 999999，那么 A 的余额就和之前的 block 记录冲突，简单一查就知道 A 在欺诈，如果 A 想要修改之前节点的数据，这个节点的摘要签名就会发生变化，通过验证签名就知道 A 在欺诈，如果 A 修改了之前所有节点的数据以及所有的摘要签名，通过验证其中几个节点和中心服务的签名就知道 A 在欺诈

因此`区块链一旦写入就不能修改`，这样可以防止很多欺诈行为

#### ⑤ 并发问题

假如全球几十亿人都在下单，那么每次下单都需要创建一个新的 block，这种情况下会导致后面的 block 产生很多分支

![并发问题1](https://github.com/yuyuyuzhang/Blog/blob/master/images/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E5%B9%B6%E5%8F%91%E9%97%AE%E9%A2%981.png)

这时会发现，这里有同步问题，最傻的方案就是使用锁解决，例如用一个集中式方法接收所有请求，这样又回到中心化设计

高明的方案就是允许商家开分支，用户和苹果店签合同，苹果店独立做一个分支联合本店所有用户的合同，这样苹果店先维护自己的区块链，等待合适的时机合并到主干分支，如果有合同合并不进去（例如余额不足），就直接作废这个合同（不发货）

![并发问题2](https://github.com/yuyuyuzhang/Blog/blob/master/images/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E5%B9%B6%E5%8F%91%E9%97%AE%E9%A2%982.png)

如果全世界每天有 1000 亿笔订单要处理，可以先拆分成 100 个区域，每个区域 10 万家店，这样最终每家店的并发量在 10000 单，可以考虑每过多长时间，就进行一次逐级合并，这样整体上每个节点的压力就不是很大了

## 5. 程序通信

程序可以是进程，可以是线程，可以是一个进程的两个部分（进程自己给自己），也可以是分布式的，程序通信是广义的交换数据

* **单机模型**：管道、本地内存共享
* **分布式模型**：远程调用、网络请求

### (1) 管道

#### ① 进程输入输出流

* **标准输入流 0**：作为进程执行的上下文，进程执行可以从标准输入流中获取数据
* **标准输出流 1**：输出的结果会被打印到屏幕上
* **标准错误流 2**：记录进程执行过程中发生异常时的异常信息

#### ② 重定向

一个进程的执行结果会写入标准输出流，进而被打印到屏幕上，这时可以使用重定向符将结果`重定向到一个文件`，这样屏幕上就不会打印结果，并且该文件也可以得到这个结果

* **覆盖重定向 >**：每次都会将目标文件覆盖
* **追加重定向 >>**：每次都是在目标文件中追加内容

#### ③ 管道

管道是将一个进程的标准输出流定向到另一个进程的标准输入流

* 管道是一个连接一个计算
* 重定向是将一个进程的执行结果重定向到一个文件

Linux 中的管道也是文件

* **匿名管道**：匿名管道只是一个`存储节点`，不属于任何目录，也就是没有路径
* **命名管道**：命名管道是一个正常的`文件`，有自己的路径

特点

* 管道具有`先进先出`特性，先流入管道文件的数据，也会先流出给管道下游的进程
* 不侵入、灵活、不会增加程序设计负担
* 能组织复杂的计算过程

### (2) 本地内存共享

本地内存共享是现代操作系统提供的能力，例如 Linux 以虚拟文件系统实现了内存共享库 shmem，从内存中划分出一块区域，供两个进程共同使用，看上去是操作文件，实际是操作内存

* **同一进程线程**：是共享进程内存的，这时无需考虑使用本地内存共享实现线程通信
* **跨进程的线程**：可以考虑使用本地内存共享实现线程通信

本地内存共享的特点

* 本地内存共享`速度快`
* 本地内存共享是一种`侵入式`的开发，需要为此撰写大量的程序，例如修改共享内存中的值需要调用 API，考虑并发控制需要处理同步问题等，因此一般不考虑本地内存共享的通信方式

### (3) 远程调用（Remote Procedure Call，RPC）

远程调用 RPC 指的是一个服务器上的应用想要调用另一个服务器上的应用提供的函数，由于不在一个服务器上，不处于一个内存空间，无法直接调用，只能`通过网络表达调用的语义和传达调用的数据`

远程调用 RPC 基于 `TCP` 协议，通过`本地程序调用`来封装`远程网络请求`的一种方式，程序员调用 RPC 时，程序看上去是在调用一个本地的方法，但是后面会有一个`服务程序 stub`将这种本地调用转换成远程网络请求，服务端收到请求后，也会有一个服务程序 stub 将请求转换成一个真实的服务端方法调用

* 客户端调用函数
* 客户端服务程序 stub 将函数调用封装成请求
* 客户端 socket 发送请求，服务端 socket 接收请求
* 服务端服务程序 stub 将请求还原成函数调用
* 执行服务端方法
* 返回结果给服务端 stub
* 服务端 stub 将返回结果封装成返回数据
* 服务端 socket 发送返回数据，客户端 socket 接收返回数据
* 客户端 socket 将返回数据传递给客户端服务程序 stub
* 客户端服务程序 stub 将返回数据转义成函数返回值

RPC 调用过程有很多`约定`，例如函数参数格式、返回结果格式、异常处理方式等等，而这些问题都比较棘手，因此实际开发通常使用`框架`，例如 Thrift 框架（Facebook 开源）、Dubbo 框架（阿里开源）、grpc（Google 开源）

RPC 真正的缺陷是`增加了系统间的耦合`，当一个系统主动调用另一个系统的方法，就意味着增加两个系统的耦合，长期增加 RPC 调用，会让系统的边界逐渐腐化

![远程调用](https://github.com/yuyuyuzhang/Blog/blob/master/images/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E8%BF%9C%E7%A8%8B%E8%B0%83%E7%94%A8.png)

### (4) 网络请求

使用基于 TCP/IP 协议群的 HTTP、HTTPS、Websocket 等协议实现通信

#### 网络请求与 RPC 的区别

* 速度：RPC 比 HTTP 等网络请求更快，虽然底层都是 TCP，但是 HTTP 协议消息比较臃肿
* 难度：RPC 的实现比较复杂，HTTP 相对比较简单
* 灵活性：RPC 需要在 API 层面进行封装，限制了开发的语言环境，必须使用统一技术栈，HTTP 不关心实现细节，跨平台跨语言，灵活性更胜一筹
* 使用场景：RPC 适合对效率要求较高，且开发过程使用统一技术栈的场景，HTTP 适合要求更加灵活，跨平台跨语言的场景
